<?xml version="1.0"?>
<!--Phoronix Test Suite v10.8.5-->
<PhoronixTestSuite>
  <Downloads>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/archive/refs/tags/b6401.tar.gz</URL>
      <MD5>e09325770a6c358ffc66e85a3f33035a</MD5>
      <SHA256>1ca48736f14d5650fc25b1661aea40b218a2701fab0220d6c31939e2e16ae239</SHA256>
      <FileName>llama.cpp-b6401.tar.gz</FileName>
      <FileSize>25655054</FileSize>
      <PlatformSpecific>Linux</PlatformSpecific>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b6401/llama-b6401-bin-ubuntu-vulkan-x64.zip</URL>
      <MD5>f2d6e1fcdf6f2b41b7b7dc301be3ad39</MD5>
      <SHA256>d68539bdd10c0e508847d194c84d01516a35d1055f50aed11d08f20f6e2e0356</SHA256>
      <FileName>llama-b6401-bin-ubuntu-vulkan-x64.zip</FileName>
      <FileSize>26986408</FileSize>
      <PlatformSpecific>Linux</PlatformSpecific>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/Llama-3.1-Tulu-3-8B-GGUF/resolve/7033c16b4f79f8708a27d80bf2ae0c6537253d1b/Llama-3.1-Tulu-3-8B-Q8_0.gguf?download=true</URL>
      <MD5>68a32ec44ea01a92c116a0b6fb83eae8</MD5>
      <SHA256>388db24ac65abaf1cd9dc9a0fc8d5aaebde5df908048b89c8cf3c2cec92562ef</SHA256>
      <FileName>Llama-3.1-Tulu-3-8B-Q8_0.gguf</FileName>
      <FileSize>8540841632</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/granite-3.0-3b-a800m-instruct-GGUF/resolve/46f75d55362bc1d5152541ec9579d38381ad7a59/granite-3.0-3b-a800m-instruct-Q8_0.gguf?download=true</URL>
      <MD5>faec97f7c662b271864eef04879d35fa</MD5>
      <SHA256>441d5c1195113695a10afb0ce7c105e9fc3c8c6d12960dab1716474326668b41</SHA256>
      <FileName>granite-3.0-3b-a800m-instruct-Q8_0.gguf</FileName>
      <FileSize>3592999808</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF/resolve/29a785419661afc70b5cd91b5023a835b0092281/Mistral-7B-Instruct-v0.3-Q8_0.gguf?download=true</URL>
      <MD5>5bc8f99351f114d3a323b9f7d1da846a</MD5>
      <SHA256>404857e776114baada71a08ebd3bba79d721ec7fca99705e7e7b892ae8bc583f</SHA256>
      <FileName>Mistral-7B-Instruct-v0.3-Q8_0.gguf</FileName>
      <FileSize>7702565088</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/c3303d94926e0e2262aacdd0fac4b18e1a29468e/gpt-oss-20b-Q8_0.gguf?download=true</URL>
      <MD5>2c43d2808623a5b1d2aac77e0fcc95d0</MD5>
      <SHA256>bcd455d4034ec02f71a875b46cb17df44a97911d7258291973be4d21f98329f3</SHA256>
      <FileName>gpt-oss-20b-Q8_0.gguf</FileName>
      <FileSize>12109567168</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/615f8936e16dfde29dcc00be71145d4d5ce8ed53/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true</URL>
      <MD5>a545602ff9947617adf6f276cdf2dc4f</MD5>
      <SHA256>8c6e3924d662d3f24a96b228a5c317510c27e91c587e71e78877ed18a875ec82</SHA256>
      <FileName>DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf</FileName>
      <FileSize>8540773088</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/Qwen3-8B-GGUF/resolve/a6adef130ffb23ddaf1a62fec9dced968c9bc482/Qwen3-8B-Q8_0.gguf?download=true</URL>
      <MD5>0bfe27bb1cf9e362688c18d209147dee</MD5>
      <SHA256>0cfbf745760f07a76ddeb358dd025a27f2e11d1ca9c9a4169a373d52990fe86e</SHA256>
      <FileName>Qwen3-8B-Q8_0.gguf</FileName>
      <FileSize>8709519168</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b6401/llama-b6401-bin-win-cpu-x64.zip</URL>
      <MD5>4ed7c552e4e6739d8fc61bfe2fdf3289</MD5>
      <SHA256>a859984dc6de981a615d7e1c4321a4f64659010274fdf29c8e0f63bd58c1e0fc</SHA256>
      <FileName>llama-b6401-bin-win-cpu-x64.zip</FileName>
      <FileSize>14955399</FileSize>
      <PlatformSpecific>Windows</PlatformSpecific>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b6401/llama-b6401-bin-win-vulkan-x64.zip</URL>
      <MD5>dc1eef51861b26cbe2ddf9372ca9dee6</MD5>
      <SHA256>1d758f95f2bac8f59d9baa487361c8425964304c1cd237be4dcfffc4f4e6170c</SHA256>
      <FileName>llama-b6401-bin-win-vulkan-x64.zip</FileName>
      <FileSize>27710602</FileSize>
      <PlatformSpecific>Windows</PlatformSpecific>
    </Package>
  </Downloads>
</PhoronixTestSuite>
