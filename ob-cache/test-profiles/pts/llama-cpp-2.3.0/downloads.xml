<?xml version="1.0"?>
<!--Phoronix Test Suite v10.8.5-->
<PhoronixTestSuite>
  <Downloads>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/archive/refs/tags/b7083.tar.gz</URL>
      <MD5>fdbfccf7d8d0db81b9748bb2bdd02442</MD5>
      <SHA256>d75ba26acf745c553347ca3aede5195e703044358dc23c767ad87f5d5c670ea4</SHA256>
      <FileName>llama.cpp-b7083.tar.gz</FileName>
      <FileSize>27238418</FileSize>
      <PlatformSpecific>Linux</PlatformSpecific>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b7083/llama-b7083-bin-ubuntu-vulkan-x64.zip</URL>
      <MD5>9e0ab1032699a8ca17f725b104a2db50</MD5>
      <SHA256>6c660b489b27deea90e6feac3d50d47002926d37790a846d039892d4f9af0289</SHA256>
      <FileName>llama-b7083-bin-ubuntu-vulkan-x64.zip</FileName>
      <FileSize>31581746</FileSize>
      <PlatformSpecific>Linux</PlatformSpecific>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/Llama-3.1-Tulu-3-8B-GGUF/resolve/7033c16b4f79f8708a27d80bf2ae0c6537253d1b/Llama-3.1-Tulu-3-8B-Q8_0.gguf?download=true</URL>
      <MD5>68a32ec44ea01a92c116a0b6fb83eae8</MD5>
      <SHA256>388db24ac65abaf1cd9dc9a0fc8d5aaebde5df908048b89c8cf3c2cec92562ef</SHA256>
      <FileName>Llama-3.1-Tulu-3-8B-Q8_0.gguf</FileName>
      <FileSize>8540841632</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/granite-3.0-3b-a800m-instruct-GGUF/resolve/46f75d55362bc1d5152541ec9579d38381ad7a59/granite-3.0-3b-a800m-instruct-Q8_0.gguf?download=true</URL>
      <MD5>faec97f7c662b271864eef04879d35fa</MD5>
      <SHA256>441d5c1195113695a10afb0ce7c105e9fc3c8c6d12960dab1716474326668b41</SHA256>
      <FileName>granite-3.0-3b-a800m-instruct-Q8_0.gguf</FileName>
      <FileSize>3592999808</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF/resolve/29a785419661afc70b5cd91b5023a835b0092281/Mistral-7B-Instruct-v0.3-Q8_0.gguf?download=true</URL>
      <MD5>5bc8f99351f114d3a323b9f7d1da846a</MD5>
      <SHA256>404857e776114baada71a08ebd3bba79d721ec7fca99705e7e7b892ae8bc583f</SHA256>
      <FileName>Mistral-7B-Instruct-v0.3-Q8_0.gguf</FileName>
      <FileSize>7702565088</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/c3303d94926e0e2262aacdd0fac4b18e1a29468e/gpt-oss-20b-Q8_0.gguf?download=true</URL>
      <MD5>2c43d2808623a5b1d2aac77e0fcc95d0</MD5>
      <SHA256>bcd455d4034ec02f71a875b46cb17df44a97911d7258291973be4d21f98329f3</SHA256>
      <FileName>gpt-oss-20b-Q8_0.gguf</FileName>
      <FileSize>12109567168</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF/resolve/615f8936e16dfde29dcc00be71145d4d5ce8ed53/DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf?download=true</URL>
      <MD5>a545602ff9947617adf6f276cdf2dc4f</MD5>
      <SHA256>8c6e3924d662d3f24a96b228a5c317510c27e91c587e71e78877ed18a875ec82</SHA256>
      <FileName>DeepSeek-R1-Distill-Llama-8B-Q8_0.gguf</FileName>
      <FileSize>8540773088</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://huggingface.co/unsloth/Qwen3-8B-GGUF/resolve/a6adef130ffb23ddaf1a62fec9dced968c9bc482/Qwen3-8B-Q8_0.gguf?download=true</URL>
      <MD5>0bfe27bb1cf9e362688c18d209147dee</MD5>
      <SHA256>0cfbf745760f07a76ddeb358dd025a27f2e11d1ca9c9a4169a373d52990fe86e</SHA256>
      <FileName>Qwen3-8B-Q8_0.gguf</FileName>
      <FileSize>8709519168</FileSize>
      <Optional>TRUE</Optional>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b7083/llama-b7083-bin-win-cpu-x64.zip</URL>
      <MD5>816a61ac134276adb367158e583c8d9f</MD5>
      <SHA256>49d5c023409e181608b16397b7cbe6ef4d1ae25287e23ca36d32961181772cdd</SHA256>
      <FileName>llama-b7083-bin-win-cpu-x64.zip</FileName>
      <FileSize>15132277</FileSize>
      <PlatformSpecific>Windows</PlatformSpecific>
    </Package>
    <Package>
      <URL>https://github.com/ggml-org/llama.cpp/releases/download/b7083/llama-b7083-bin-win-vulkan-x64.zip</URL>
      <MD5>eeee747dfddfdb2b5516e50af94eab33</MD5>
      <SHA256>8ffe88d9ece3c803948953b911538c9fb81d30712c157ff05a771382ae1ca6df</SHA256>
      <FileName>llama-b7083-bin-win-vulkan-x64.zip</FileName>
      <FileSize>29056757</FileSize>
      <PlatformSpecific>Windows</PlatformSpecific>
    </Package>
  </Downloads>
</PhoronixTestSuite>
